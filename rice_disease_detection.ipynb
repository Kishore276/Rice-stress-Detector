{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce135ae3",
   "metadata": {},
   "source": [
    "# Rice Plant Stress Detection using Deep Learning\n",
    "## CNN-based Multi-class Classification System\n",
    "\n",
    "This notebook implements a Convolutional Neural Network for detecting different types of stress in rice plants including:\n",
    "- Bacterial Blight\n",
    "- Blast Disease\n",
    "- Brown Spot\n",
    "- Tungro Virus\n",
    "\n",
    "**Author:** kishore\n",
    "**Date:** October 30, 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2192478",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902faaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0, ResNet50V2, MobileNetV2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure GPU\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    # Use GPU 1 as requested\n",
    "    tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print(f\"✓ GPU Enabled: {tf.test.gpu_device_name()}\")\n",
    "    print(f\"✓ GPU Details: {physical_devices}\")\n",
    "else:\n",
    "    print(\"⚠ No GPU detected, using CPU\")\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4ab7d2",
   "metadata": {},
   "source": [
    "## 2. Data Configuration and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "BASE_DIR = Path(r'c:\\Users\\gyuva\\Downloads\\cap')\n",
    "DATASET_DIR = BASE_DIR / 'Rice Leaf Disease Images'\n",
    "MODEL_DIR = BASE_DIR / 'models'\n",
    "RESULTS_DIR = BASE_DIR / 'results'\n",
    "\n",
    "# Create directories\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Model hyperparameters\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['Bacterialblight', 'Blast', 'Brownspot', 'Tungro']\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "print(f\"Dataset Directory: {DATASET_DIR}\")\n",
    "print(f\"Model Directory: {MODEL_DIR}\")\n",
    "print(f\"Number of Classes: {NUM_CLASSES}\")\n",
    "print(f\"Classes: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba66a1f",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2  # 80% train, 20% validation\n",
    ")\n",
    "\n",
    "# No augmentation for validation/test data\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "# Load training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    DATASET_DIR,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"Class indices: {train_generator.class_indices}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d1926",
   "metadata": {},
   "source": [
    "## 4. Visualize Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59098289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "def plot_sample_images():\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    fig.suptitle('Sample Images from Each Disease Class', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, disease in enumerate(CLASS_NAMES):\n",
    "        disease_dir = DATASET_DIR / disease\n",
    "        images = list(disease_dir.glob('*.jpg'))[:2]\n",
    "        \n",
    "        for j, img_path in enumerate(images):\n",
    "            img = cv2.imread(str(img_path))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            axes[j, i].imshow(img)\n",
    "            axes[j, i].set_title(disease, fontweight='bold')\n",
    "            axes[j, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'sample_images.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_sample_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45eddb80",
   "metadata": {},
   "source": [
    "## 5. Build Custom CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888e85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_cnn():\n",
    "    \"\"\"\n",
    "    Custom CNN architecture optimized for rice disease detection\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "        \n",
    "        # Block 1\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 2\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 3\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Block 4\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Fully connected layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Output layer\n",
    "        layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model\n",
    "model = create_custom_cnn()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b0bc5",
   "metadata": {},
   "source": [
    "## 6. Transfer Learning Model (Alternative Approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f367030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_learning_model(base_model_name='EfficientNetB0'):\n",
    "    \"\"\"\n",
    "    Create transfer learning model using pre-trained networks\n",
    "    \"\"\"\n",
    "    # Load base model\n",
    "    if base_model_name == 'EfficientNetB0':\n",
    "        base_model = EfficientNetB0(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "        )\n",
    "    elif base_model_name == 'ResNet50V2':\n",
    "        base_model = ResNet50V2(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "        )\n",
    "    else:\n",
    "        base_model = MobileNetV2(\n",
    "            include_top=False,\n",
    "            weights='imagenet',\n",
    "            input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "        )\n",
    "    \n",
    "    # Freeze base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Build model\n",
    "    inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "    \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Uncomment to use transfer learning instead\n",
    "# model = create_transfer_learning_model('EfficientNetB0')\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5bbdf6",
   "metadata": {},
   "source": [
    "## 7. Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afff894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', \n",
    "             keras.metrics.Precision(name='precision'),\n",
    "             keras.metrics.Recall(name='recall'),\n",
    "             keras.metrics.AUC(name='auc')]\n",
    ")\n",
    "\n",
    "print(\"✓ Model compiled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee27346",
   "metadata": {},
   "source": [
    "## 8. Setup Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d30f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "callbacks = [\n",
    "    # Save best model\n",
    "    ModelCheckpoint(\n",
    "        filepath=str(MODEL_DIR / f'rice_disease_model_best_{timestamp}.h5'),\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Early stopping\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard\n",
    "    TensorBoard(\n",
    "        log_dir=str(RESULTS_DIR / f'logs_{timestamp}'),\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"✓ Callbacks configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e787b",
   "metadata": {},
   "source": [
    "## 9. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d20773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING STARTED\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING COMPLETED\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba213ce",
   "metadata": {},
   "source": [
    "## 10. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3c1094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model in multiple formats\n",
    "final_model_path = MODEL_DIR / 'rice_disease_model_final.h5'\n",
    "model.save(final_model_path)\n",
    "print(f\"✓ Model saved: {final_model_path}\")\n",
    "\n",
    "# Save in TensorFlow SavedModel format\n",
    "saved_model_path = MODEL_DIR / 'rice_disease_saved_model'\n",
    "model.save(saved_model_path)\n",
    "print(f\"✓ SavedModel saved: {saved_model_path}\")\n",
    "\n",
    "# Save model architecture as JSON\n",
    "model_json = model.to_json()\n",
    "with open(MODEL_DIR / 'model_architecture.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "print(f\"✓ Model architecture saved\")\n",
    "\n",
    "# Save class names\n",
    "with open(MODEL_DIR / 'class_names.json', 'w') as f:\n",
    "    json.dump(CLASS_NAMES, f)\n",
    "print(f\"✓ Class names saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea25a4",
   "metadata": {},
   "source": [
    "## 11. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92faca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation metrics\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Accuracy\n",
    "    axes[0, 0].plot(history.history['accuracy'], label='Train Accuracy', linewidth=2)\n",
    "    axes[0, 0].plot(history.history['val_accuracy'], label='Val Accuracy', linewidth=2)\n",
    "    axes[0, 0].set_title('Model Accuracy', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Accuracy')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 1].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 1].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, 1].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Precision\n",
    "    axes[1, 0].plot(history.history['precision'], label='Train Precision', linewidth=2)\n",
    "    axes[1, 0].plot(history.history['val_precision'], label='Val Precision', linewidth=2)\n",
    "    axes[1, 0].set_title('Model Precision', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Precision')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Recall\n",
    "    axes[1, 1].plot(history.history['recall'], label='Train Recall', linewidth=2)\n",
    "    axes[1, 1].plot(history.history['val_recall'], label='Val Recall', linewidth=2)\n",
    "    axes[1, 1].set_title('Model Recall', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Recall')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RESULTS_DIR / 'training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d50a2cf",
   "metadata": {},
   "source": [
    "## 12. Evaluate Model on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec31b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print(\"Evaluating model on validation set...\")\n",
    "val_loss, val_accuracy, val_precision, val_recall, val_auc = model.evaluate(validation_generator, verbose=1)\n",
    "\n",
    "# Calculate F1 Score\n",
    "val_f1 = 2 * (val_precision * val_recall) / (val_precision + val_recall)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Accuracy:  {val_accuracy:.4f} ({val_accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {val_precision:.4f}\")\n",
    "print(f\"Recall:    {val_recall:.4f}\")\n",
    "print(f\"F1-Score:  {val_f1:.4f}\")\n",
    "print(f\"AUC:       {val_auc:.4f}\")\n",
    "print(f\"Loss:      {val_loss:.4f}\")\n",
    "print(\"=\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09882b2b",
   "metadata": {},
   "source": [
    "## 13. Generate Predictions and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f09a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "validation_generator.reset()\n",
    "y_pred_probs = model.predict(validation_generator, verbose=1)\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "y_true = validation_generator.classes\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.title('Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Normalized confusion matrix\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='RdYlGn',\n",
    "            xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES,\n",
    "            cbar_kws={'label': 'Percentage'})\n",
    "plt.title('Normalized Confusion Matrix', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'confusion_matrix_normalized.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27df139",
   "metadata": {},
   "source": [
    "## 14. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee2791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed classification report\n",
    "report = classification_report(y_true, y_pred, target_names=CLASS_NAMES, digits=4)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(report)\n",
    "\n",
    "# Save report to file\n",
    "with open(RESULTS_DIR / 'classification_report.txt', 'w') as f:\n",
    "    f.write(report)\n",
    "\n",
    "# Get detailed metrics per class\n",
    "report_dict = classification_report(y_true, y_pred, target_names=CLASS_NAMES, output_dict=True)\n",
    "df_report = pd.DataFrame(report_dict).transpose()\n",
    "df_report.to_csv(RESULTS_DIR / 'classification_report.csv')\n",
    "print(\"\\n✓ Classification report saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40148942",
   "metadata": {},
   "source": [
    "## 15. Save Training Metrics and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c5530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save comprehensive results\n",
    "results = {\n",
    "    'model_architecture': 'Custom CNN',\n",
    "    'timestamp': timestamp,\n",
    "    'dataset': {\n",
    "        'total_samples': train_generator.samples + validation_generator.samples,\n",
    "        'training_samples': train_generator.samples,\n",
    "        'validation_samples': validation_generator.samples,\n",
    "        'num_classes': NUM_CLASSES,\n",
    "        'class_names': CLASS_NAMES\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'image_size': f'{IMG_HEIGHT}x{IMG_WIDTH}',\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs_trained': len(history.history['loss']),\n",
    "        'initial_learning_rate': LEARNING_RATE\n",
    "    },\n",
    "    'final_metrics': {\n",
    "        'validation_accuracy': float(val_accuracy),\n",
    "        'validation_precision': float(val_precision),\n",
    "        'validation_recall': float(val_recall),\n",
    "        'validation_f1_score': float(val_f1),\n",
    "        'validation_auc': float(val_auc),\n",
    "        'validation_loss': float(val_loss)\n",
    "    },\n",
    "    'per_class_metrics': report_dict,\n",
    "    'training_history': {\n",
    "        'train_accuracy': [float(x) for x in history.history['accuracy']],\n",
    "        'val_accuracy': [float(x) for x in history.history['val_accuracy']],\n",
    "        'train_loss': [float(x) for x in history.history['loss']],\n",
    "        'val_loss': [float(x) for x in history.history['val_loss']]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results as JSON\n",
    "with open(RESULTS_DIR / 'training_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"✓ All results saved successfully\")\n",
    "print(f\"\\nResults directory: {RESULTS_DIR}\")\n",
    "print(f\"Model directory: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1154741",
   "metadata": {},
   "source": [
    "## 16. Test Single Image Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86d7bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image(image_path, model):\n",
    "    \"\"\"\n",
    "    Predict disease for a single image\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (IMG_HEIGHT, IMG_WIDTH))\n",
    "    img_array = np.expand_dims(img_resized / 255.0, axis=0)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(img_array, verbose=0)\n",
    "    predicted_class_idx = np.argmax(predictions[0])\n",
    "    confidence = predictions[0][predicted_class_idx]\n",
    "    predicted_class = CLASS_NAMES[predicted_class_idx]\n",
    "    \n",
    "    # Get all probabilities\n",
    "    all_probs = {CLASS_NAMES[i]: float(predictions[0][i]) for i in range(NUM_CLASSES)}\n",
    "    \n",
    "    return predicted_class, confidence, all_probs, img_rgb\n",
    "\n",
    "# Test with sample images\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "for i, disease in enumerate(CLASS_NAMES):\n",
    "    sample_img = list((DATASET_DIR / disease).glob('*.jpg'))[0]\n",
    "    pred_class, conf, probs, img = predict_single_image(sample_img, model)\n",
    "    \n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'True: {disease}\\nPredicted: {pred_class}\\nConfidence: {conf:.2%}', \n",
    "                     fontweight='bold', fontsize=10)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(RESULTS_DIR / 'sample_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Prediction function tested successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b6d19f",
   "metadata": {},
   "source": [
    "## 17. Create Treatment Recommendations Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a791fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment recommendations for each disease\n",
    "treatment_recommendations = {\n",
    "    \"Bacterialblight\": {\n",
    "        \"disease_name\": \"Bacterial Blight\",\n",
    "        \"description\": \"Bacterial blight is caused by Xanthomonas oryzae pv. oryzae, resulting in wilting and drying of leaves.\",\n",
    "        \"symptoms\": [\n",
    "            \"Water-soaked lesions on leaf tips and margins\",\n",
    "            \"Yellow to white lesions with wavy edges\",\n",
    "            \"Wilting of seedlings (kresek phase)\",\n",
    "            \"Systemic infection causing plant death\"\n",
    "        ],\n",
    "        \"precautions\": [\n",
    "            \"Use disease-free seeds\",\n",
    "            \"Avoid excessive nitrogen fertilization\",\n",
    "            \"Maintain proper water management\",\n",
    "            \"Remove and destroy infected plants\",\n",
    "            \"Practice crop rotation\"\n",
    "        ],\n",
    "        \"treatment\": [\n",
    "            \"Apply copper-based bactericides\",\n",
    "            \"Use resistant varieties (e.g., IR64, IR72)\",\n",
    "            \"Spray streptocycline (200-300 ppm) at 7-10 day intervals\",\n",
    "            \"Apply zinc sulfate (0.5%) to strengthen plants\"\n",
    "        ],\n",
    "        \"fertilizer\": \"Balanced NPK (10-26-26) with emphasis on potassium\",\n",
    "        \"water_management\": \"Avoid over-irrigation; maintain 2-5 cm water depth\",\n",
    "        \"severity\": \"High\"\n",
    "    },\n",
    "    \"Blast\": {\n",
    "        \"disease_name\": \"Rice Blast\",\n",
    "        \"description\": \"Rice blast is caused by fungus Magnaporthe oryzae, one of the most destructive rice diseases worldwide.\",\n",
    "        \"symptoms\": [\n",
    "            \"Diamond-shaped lesions with gray centers and brown margins\",\n",
    "            \"Leaf blast: spots on leaves\",\n",
    "            \"Neck blast: infection at neck node\",\n",
    "            \"Panicle blast: incomplete grain filling\"\n",
    "        ],\n",
    "        \"precautions\": [\n",
    "            \"Use certified disease-free seeds\",\n",
    "            \"Avoid excessive nitrogen application\",\n",
    "            \"Ensure proper spacing between plants\",\n",
    "            \"Remove infected stubble and debris\",\n",
    "            \"Use silicon amendments to strengthen plants\"\n",
    "        ],\n",
    "        \"treatment\": [\n",
    "            \"Apply Tricyclazole 75% WP @ 0.6 g/liter\",\n",
    "            \"Spray Carbendazim 50% WP @ 1 g/liter\",\n",
    "            \"Use Azoxystrobin 25% SC @ 1 ml/liter\",\n",
    "            \"Apply organic fungicides like neem oil (3-5%)\"\n",
    "        ],\n",
    "        \"fertilizer\": \"Split application of nitrogen; use potassium silicate\",\n",
    "        \"water_management\": \"Intermittent irrigation to reduce humidity\",\n",
    "        \"severity\": \"Very High\"\n",
    "    },\n",
    "    \"Brownspot\": {\n",
    "        \"disease_name\": \"Brown Spot\",\n",
    "        \"description\": \"Brown spot is caused by fungus Bipolaris oryzae, often associated with nutrient deficiency.\",\n",
    "        \"symptoms\": [\n",
    "            \"Circular to oval brown spots on leaves\",\n",
    "            \"Spots with gray or whitish centers\",\n",
    "            \"Numerous spots causing leaf withering\",\n",
    "            \"Affects grain quality and yield\"\n",
    "        ],\n",
    "        \"precautions\": [\n",
    "            \"Treat seeds with fungicides before sowing\",\n",
    "            \"Ensure adequate soil nutrition\",\n",
    "            \"Avoid water stress conditions\",\n",
    "            \"Maintain proper plant spacing\",\n",
    "            \"Remove infected plant debris\"\n",
    "        ],\n",
    "        \"treatment\": [\n",
    "            \"Spray Mancozeb 75% WP @ 2.5 g/liter\",\n",
    "            \"Apply Propiconazole 25% EC @ 1 ml/liter\",\n",
    "            \"Use Copper oxychloride 50% WP @ 3 g/liter\",\n",
    "            \"Seed treatment with Carbendazim @ 2 g/kg seed\"\n",
    "        ],\n",
    "        \"fertilizer\": \"Apply NPK (20-10-10) with micronutrients (Zinc, Iron)\",\n",
    "        \"water_management\": \"Maintain consistent moisture; avoid drought stress\",\n",
    "        \"severity\": \"Moderate\"\n",
    "    },\n",
    "    \"Tungro\": {\n",
    "        \"disease_name\": \"Tungro Virus\",\n",
    "        \"description\": \"Tungro is a viral disease transmitted by green leafhoppers, causing severe yield loss.\",\n",
    "        \"symptoms\": [\n",
    "            \"Yellow or orange-yellow discoloration of leaves\",\n",
    "            \"Stunted plant growth\",\n",
    "            \"Reduced tillering\",\n",
    "            \"Delayed flowering and incomplete panicle formation\"\n",
    "        ],\n",
    "        \"precautions\": [\n",
    "            \"Control vector (green leafhopper) population\",\n",
    "            \"Use resistant varieties\",\n",
    "            \"Remove infected plants immediately\",\n",
    "            \"Avoid staggered planting\",\n",
    "            \"Synchronize planting dates in community\"\n",
    "        ],\n",
    "        \"treatment\": [\n",
    "            \"No direct cure; focus on vector control\",\n",
    "            \"Spray Imidacloprid 17.8% SL @ 0.3 ml/liter for leafhopper\",\n",
    "            \"Apply Thiamethoxam 25% WG @ 0.2 g/liter\",\n",
    "            \"Use light traps to monitor and control vectors\",\n",
    "            \"Remove and destroy infected plants\"\n",
    "        ],\n",
    "        \"fertilizer\": \"Moderate nitrogen; increase potassium for plant vigor\",\n",
    "        \"water_management\": \"Maintain shallow water depth (2-3 cm)\",\n",
    "        \"severity\": \"Very High\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save recommendations\n",
    "with open(MODEL_DIR / 'treatment_recommendations.json', 'w') as f:\n",
    "    json.dump(treatment_recommendations, f, indent=2)\n",
    "\n",
    "print(\"✓ Treatment recommendations database created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ce16b",
   "metadata": {},
   "source": [
    "## 18. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d795b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PROJECT SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Project: Rice Plant Stress Detection System\")\n",
    "print(f\"Model Type: Custom CNN\")\n",
    "print(f\"Total Parameters: {model.count_params():,}\")\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(f\"  - Total Images: {train_generator.samples + validation_generator.samples:,}\")\n",
    "print(f\"  - Training: {train_generator.samples:,} images\")\n",
    "print(f\"  - Validation: {validation_generator.samples:,} images\")\n",
    "print(f\"  - Classes: {NUM_CLASSES}\")\n",
    "print(f\"\\nFinal Model Performance:\")\n",
    "print(f\"  - Accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"  - Precision: {val_precision:.4f}\")\n",
    "print(f\"  - Recall: {val_recall:.4f}\")\n",
    "print(f\"  - F1-Score: {val_f1:.4f}\")\n",
    "print(f\"\\nFiles Generated:\")\n",
    "print(f\"  - Model: rice_disease_model_final.h5\")\n",
    "print(f\"  - SavedModel: rice_disease_saved_model/\")\n",
    "print(f\"  - Treatment DB: treatment_recommendations.json\")\n",
    "print(f\"  - Results: training_results.json\")\n",
    "print(f\"  - Visualizations: *.png files\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "print(\"✓ Training pipeline completed successfully!\")\n",
    "print(\"✓ Model is ready for deployment\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Deploy model to web application\")\n",
    "print(\"2. Test with real-world images\")\n",
    "print(\"3. Monitor and retrain as needed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
