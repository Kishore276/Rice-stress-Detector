{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae80500",
   "metadata": {},
   "source": [
    "# ðŸŒ¾ Rice Disease Detection - Model Training (Google Colab)\n",
    "\n",
    "This notebook will train the CNN model on your rice disease dataset.\n",
    "\n",
    "**Your dataset:** Already linked from Google Drive! âœ…\n",
    "\n",
    "**Steps:**\n",
    "1. Click `Runtime â†’ Change runtime type â†’ GPU`\n",
    "2. Run all cells (Ctrl+F9 or Runtime â†’ Run all)\n",
    "3. Wait 10-15 minutes for training\n",
    "4. Download the trained model files\n",
    "5. Place in your local `models/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013362f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q tensorflow numpy pillow matplotlib seaborn scikit-learn gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip dataset from Google Drive\n",
    "import zipfile\n",
    "import os\n",
    "import gdown\n",
    "\n",
    "# Your dataset file ID from Google Drive\n",
    "file_id = '1YcJ_spCXpE9IfvhuLz31h2kzx5oF9Dky'\n",
    "output_zip = '/content/rice_dataset.zip'\n",
    "\n",
    "# Download from Google Drive\n",
    "print(\"ðŸ“¥ Downloading dataset from Google Drive...\")\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "gdown.download(url, output_zip, quiet=False)\n",
    "\n",
    "# Extract dataset\n",
    "print(\"\\nðŸ“¦ Extracting dataset...\")\n",
    "with zipfile.ZipFile(output_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/')\n",
    "\n",
    "print(\"\\nâœ… Dataset ready!\")\n",
    "!ls -la /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b322066d",
   "metadata": {},
   "source": [
    "## âš ï¸ Important Note\n",
    "After running the download cell above, check the output to see the exact folder name. If the folder is named differently (like \"rice_dataset\" instead of \"Rice Leaf Disease Images\"), the next cell will auto-detect it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training code\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Auto-detect dataset directory\n",
    "import glob\n",
    "possible_dirs = glob.glob('/content/*Rice*') + glob.glob('/content/*rice*')\n",
    "if possible_dirs:\n",
    "    DATA_DIR = possible_dirs[0]\n",
    "    print(f\"âœ… Found dataset at: {DATA_DIR}\")\n",
    "else:\n",
    "    DATA_DIR = \"/content/Rice Leaf Disease Images\"\n",
    "    print(f\"âš ï¸ Using default path: {DATA_DIR}\")\n",
    "\n",
    "# Check GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"ðŸŽ® GPU Available: {len(gpus) > 0}\")\n",
    "if gpus:\n",
    "    print(f\"   GPU: {gpus[0].name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "num_classes = len(class_names)\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b497362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(224, 224, 3)),\n",
    "    \n",
    "    # Block 1\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Block 2\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Block 3\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Block 4\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d177978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c55278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model and Class Indices\n",
    "model.save('rice_disease_model.h5')\n",
    "\n",
    "class_indices = {v: k for k, v in train_generator.class_indices.items()}\n",
    "with open('class_indices.json', 'w') as f:\n",
    "    json.dump(class_indices, f, indent=4)\n",
    "\n",
    "print(\"âœ“ Model saved\")\n",
    "print(\"âœ“ Class indices saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b693b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"\\nValidation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aac892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "val_generator.reset()\n",
    "y_pred_proba = model.predict(val_generator)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b828bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Curves\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c56cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading trained model...\")\n",
    "files.download('rice_disease_model.h5')\n",
    "files.download('class_indices.json')\n",
    "files.download('confusion_matrix.png')\n",
    "files.download('training_curves.png')\n",
    "\n",
    "print(\"\\nâœ“ All files downloaded!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Place 'rice_disease_model.h5' in your local 'models/' folder\")\n",
    "print(\"2. Place 'class_indices.json' in your local 'models/' folder\")\n",
    "print(\"3. Run: python app_simple.py\")\n",
    "print(\"4. Open: http://localhost:5000\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
