{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ae80500",
   "metadata": {},
   "source": [
    "# 🌾 Rice Disease Detection - Model Training (Google Colab)\n",
    "\n",
    "This notebook will train the CNN model on your rice disease dataset.\n",
    "\n",
    "**Your dataset:** Already linked from Google Drive! ✅\n",
    "\n",
    "**Steps:**\n",
    "1. Click `Runtime → Change runtime type → GPU`\n",
    "2. Run all cells (Ctrl+F9 or Runtime → Run all)\n",
    "3. Wait 10-15 minutes for training\n",
    "4. Download the trained model files\n",
    "5. Place in your local `models/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013362f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q tensorflow numpy pillow matplotlib seaborn scikit-learn gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and unzip dataset from Google Drive\n",
    "import zipfile\n",
    "import os\n",
    "import gdown\n",
    "\n",
    "# Your dataset file ID from Google Drive\n",
    "file_id = '1YcJ_spCXpE9IfvhuLz31h2kzx5oF9Dky'\n",
    "output_zip = '/content/rice_dataset.zip'\n",
    "\n",
    "# Download from Google Drive\n",
    "print(\"📥 Downloading dataset from Google Drive...\")\n",
    "url = f'https://drive.google.com/uc?id={file_id}'\n",
    "gdown.download(url, output_zip, quiet=False)\n",
    "\n",
    "# Extract dataset\n",
    "print(\"\\n📦 Extracting dataset...\")\n",
    "with zipfile.ZipFile(output_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/')\n",
    "\n",
    "print(\"\\n✅ Dataset ready!\")\n",
    "!ls -la /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b322066d",
   "metadata": {},
   "source": [
    "## ⚠️ Important Note\n",
    "After running the download cell above, check the output to see the exact folder name. If the folder is named differently (like \"rice_dataset\" instead of \"Rice Leaf Disease Images\"), the next cell will auto-detect it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training code\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# Auto-detect dataset directory\n",
    "import glob\n",
    "possible_dirs = glob.glob('/content/*Rice*') + glob.glob('/content/*rice*')\n",
    "if possible_dirs:\n",
    "    DATA_DIR = possible_dirs[0]\n",
    "    print(f\"✅ Found dataset at: {DATA_DIR}\")\n",
    "else:\n",
    "    DATA_DIR = \"/content/Rice Leaf Disease Images\"\n",
    "    print(f\"⚠️ Using default path: {DATA_DIR}\")\n",
    "\n",
    "# Check GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"🎮 GPU Available: {len(gpus) > 0}\")\n",
    "if gpus:\n",
    "    print(f\"   GPU: {gpus[0].name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4de6d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "num_classes = len(class_names)\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {val_generator.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b497362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(224, 224, 3)),\n",
    "    \n",
    "    # Block 1\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    # Block 2\n",
    "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Block 3\n",
    "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.25),\n",
    "    \n",
    "    # Block 4\n",
    "    layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    # Dense layers\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d177978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c55278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[checkpoint, early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e7711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model and Class Indices\n",
    "model.save('rice_disease_model.h5')\n",
    "\n",
    "class_indices = {v: k for k, v in train_generator.class_indices.items()}\n",
    "with open('class_indices.json', 'w') as f:\n",
    "    json.dump(class_indices, f, indent=4)\n",
    "\n",
    "print(\"✓ Model saved\")\n",
    "print(\"✓ Class indices saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b693b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f\"\\nValidation Accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aac892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "val_generator.reset()\n",
    "y_pred_proba = model.predict(val_generator)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b828bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Curves\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c56cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading trained model...\")\n",
    "files.download('rice_disease_model.h5')\n",
    "files.download('class_indices.json')\n",
    "files.download('confusion_matrix.png')\n",
    "files.download('training_curves.png')\n",
    "\n",
    "print(\"\\n✓ All files downloaded!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Place 'rice_disease_model.h5' in your local 'models/' folder\")\n",
    "print(\"2. Place 'class_indices.json' in your local 'models/' folder\")\n",
    "print(\"3. Run: python app_simple.py\")\n",
    "print(\"4. Open: http://localhost:5000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403ac09",
   "metadata": {},
   "source": [
    "# 📊 Detailed Training Analysis & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e502660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Training History Visualization\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create figure with multiple subplots\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "\n",
    "# 1. Accuracy Comparison\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "plt.plot(history.history['accuracy'], marker='o', linewidth=2, label='Training Accuracy', color='#2ecc71')\n",
    "plt.plot(history.history['val_accuracy'], marker='s', linewidth=2, label='Validation Accuracy', color='#e74c3c')\n",
    "plt.title('Model Accuracy Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim([0, 1.05])\n",
    "\n",
    "# 2. Loss Comparison\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "plt.plot(history.history['loss'], marker='o', linewidth=2, label='Training Loss', color='#3498db')\n",
    "plt.plot(history.history['val_loss'], marker='s', linewidth=2, label='Validation Loss', color='#f39c12')\n",
    "plt.title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.legend(loc='upper right', fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Accuracy Difference (Overfitting Detection)\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "acc_diff = [train - val for train, val in zip(history.history['accuracy'], history.history['val_accuracy'])]\n",
    "plt.plot(acc_diff, marker='d', linewidth=2, color='#9b59b6')\n",
    "plt.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "plt.title('Train-Val Accuracy Gap (Overfitting Check)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Accuracy Difference', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Learning Rate Changes (if available)\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "if 'lr' in history.history:\n",
    "    plt.plot(history.history['lr'], marker='o', linewidth=2, color='#e67e22')\n",
    "    plt.title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Epoch', fontsize=12)\n",
    "    plt.ylabel('Learning Rate', fontsize=12)\n",
    "    plt.yscale('log')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Learning Rate\\nNot Tracked', \n",
    "             ha='center', va='center', fontsize=14, transform=ax4.transAxes)\n",
    "    plt.axis('off')\n",
    "\n",
    "# 5. Metrics Bar Chart (Final Epoch)\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "final_metrics = {\n",
    "    'Train\\nAccuracy': history.history['accuracy'][-1],\n",
    "    'Val\\nAccuracy': history.history['val_accuracy'][-1],\n",
    "    'Train\\nLoss': history.history['loss'][-1],\n",
    "    'Val\\nLoss': history.history['val_loss'][-1]\n",
    "}\n",
    "colors = ['#2ecc71', '#e74c3c', '#3498db', '#f39c12']\n",
    "bars = plt.bar(final_metrics.keys(), final_metrics.values(), color=colors, alpha=0.8, edgecolor='black')\n",
    "plt.title('Final Epoch Metrics', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Value', fontsize=12)\n",
    "plt.xticks(rotation=0, fontsize=10)\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{height:.4f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 6. Best Epoch Highlight\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "best_epoch = np.argmax(history.history['val_accuracy'])\n",
    "best_val_acc = history.history['val_accuracy'][best_epoch]\n",
    "best_val_loss = history.history['val_loss'][best_epoch]\n",
    "best_train_acc = history.history['accuracy'][best_epoch]\n",
    "best_train_loss = history.history['loss'][best_epoch]\n",
    "\n",
    "info_text = f\"\"\"\n",
    "BEST MODEL PERFORMANCE\n",
    "━━━━━━━━━━━━━━━━━━━━━━━━━\n",
    "Epoch: {best_epoch + 1}/{len(history.history['accuracy'])}\n",
    "\n",
    "Validation Metrics:\n",
    "  • Accuracy: {best_val_acc:.4f} ({best_val_acc*100:.2f}%)\n",
    "  • Loss: {best_val_loss:.4f}\n",
    "\n",
    "Training Metrics:\n",
    "  • Accuracy: {best_train_acc:.4f} ({best_train_acc*100:.2f}%)\n",
    "  • Loss: {best_train_loss:.4f}\n",
    "\n",
    "Overfitting Gap: {(best_train_acc - best_val_acc)*100:.2f}%\n",
    "\"\"\"\n",
    "plt.text(0.1, 0.5, info_text, fontsize=11, family='monospace',\n",
    "         verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('detailed_training_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Detailed training analysis graph saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b8cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📋 Table 1: Epoch-by-Epoch Training History\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Create comprehensive training history DataFrame\n",
    "epochs_data = {\n",
    "    'Epoch': list(range(1, len(history.history['accuracy']) + 1)),\n",
    "    'Training Accuracy': [f\"{acc:.4f}\" for acc in history.history['accuracy']],\n",
    "    'Validation Accuracy': [f\"{acc:.4f}\" for acc in history.history['val_accuracy']],\n",
    "    'Training Loss': [f\"{loss:.4f}\" for loss in history.history['loss']],\n",
    "    'Validation Loss': [f\"{loss:.4f}\" for loss in history.history['val_loss']],\n",
    "    'Acc Improvement': ['N/A'] + [f\"{(history.history['val_accuracy'][i] - history.history['val_accuracy'][i-1])*100:+.2f}%\" \n",
    "                                   for i in range(1, len(history.history['val_accuracy']))]\n",
    "}\n",
    "\n",
    "df_epochs = pd.DataFrame(epochs_data)\n",
    "\n",
    "# Highlight best epoch\n",
    "best_epoch_idx = np.argmax(history.history['val_accuracy'])\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"📊 COMPLETE TRAINING HISTORY - EPOCH BY EPOCH\")\n",
    "print(\"=\"*100)\n",
    "print(f\"\\n🏆 Best Epoch: {best_epoch_idx + 1} with Validation Accuracy: {history.history['val_accuracy'][best_epoch_idx]:.4f}\\n\")\n",
    "\n",
    "# Style the dataframe\n",
    "def highlight_best_epoch(row):\n",
    "    if row['Epoch'] == best_epoch_idx + 1:\n",
    "        return ['background-color: #90EE90; font-weight: bold'] * len(row)\n",
    "    else:\n",
    "        return [''] * len(row)\n",
    "\n",
    "styled_df = df_epochs.style.apply(highlight_best_epoch, axis=1)\\\n",
    "    .set_properties(**{\n",
    "        'text-align': 'center',\n",
    "        'border': '1px solid black',\n",
    "        'font-size': '11px'\n",
    "    })\\\n",
    "    .set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#4CAF50'), \n",
    "                                      ('color', 'white'), \n",
    "                                      ('font-weight', 'bold'),\n",
    "                                      ('text-align', 'center'),\n",
    "                                      ('border', '1px solid black')]}\n",
    "    ])\n",
    "\n",
    "display(styled_df)\n",
    "\n",
    "# Save to CSV\n",
    "df_epochs.to_csv('training_history.csv', index=False)\n",
    "print(\"\\n✅ Training history saved to 'training_history.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947d398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📋 Table 2: Model Performance Summary\n",
    "print(\"=\"*100)\n",
    "print(\"📈 MODEL PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Training Configuration\n",
    "config_data = {\n",
    "    'Parameter': ['Total Epochs', 'Epochs Completed', 'Batch Size', 'Image Size', \n",
    "                  'Training Samples', 'Validation Samples', 'Classes', 'Learning Rate'],\n",
    "    'Value': [\n",
    "        EPOCHS,\n",
    "        len(history.history['accuracy']),\n",
    "        BATCH_SIZE,\n",
    "        f\"{IMG_SIZE}x{IMG_SIZE}\",\n",
    "        train_generator.samples,\n",
    "        val_generator.samples,\n",
    "        num_classes,\n",
    "        LEARNING_RATE\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_config = pd.DataFrame(config_data)\n",
    "\n",
    "print(\"\\n🔧 TRAINING CONFIGURATION\")\n",
    "print(\"─\"*50)\n",
    "display(df_config.style.hide(axis='index').set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'border': '1px solid black',\n",
    "    'font-size': '12px'\n",
    "}).set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#2196F3'), \n",
    "                                  ('color', 'white'), \n",
    "                                  ('font-weight', 'bold'),\n",
    "                                  ('border', '1px solid black')]}\n",
    "]))\n",
    "\n",
    "# Performance Metrics\n",
    "metrics_data = {\n",
    "    'Metric': [\n",
    "        'Best Validation Accuracy',\n",
    "        'Best Validation Loss',\n",
    "        'Final Validation Accuracy',\n",
    "        'Final Validation Loss',\n",
    "        'Best Training Accuracy',\n",
    "        'Best Training Loss',\n",
    "        'Final Training Accuracy',\n",
    "        'Final Training Loss',\n",
    "        'Best Epoch Number',\n",
    "        'Overfitting Gap (Train-Val Acc)',\n",
    "        'Model Converged',\n",
    "        'Early Stopping Triggered'\n",
    "    ],\n",
    "    'Value': [\n",
    "        f\"{max(history.history['val_accuracy']):.4f} ({max(history.history['val_accuracy'])*100:.2f}%)\",\n",
    "        f\"{min(history.history['val_loss']):.4f}\",\n",
    "        f\"{history.history['val_accuracy'][-1]:.4f} ({history.history['val_accuracy'][-1]*100:.2f}%)\",\n",
    "        f\"{history.history['val_loss'][-1]:.4f}\",\n",
    "        f\"{max(history.history['accuracy']):.4f} ({max(history.history['accuracy'])*100:.2f}%)\",\n",
    "        f\"{min(history.history['loss']):.4f}\",\n",
    "        f\"{history.history['accuracy'][-1]:.4f} ({history.history['accuracy'][-1]*100:.2f}%)\",\n",
    "        f\"{history.history['loss'][-1]:.4f}\",\n",
    "        np.argmax(history.history['val_accuracy']) + 1,\n",
    "        f\"{(max(history.history['accuracy']) - max(history.history['val_accuracy']))*100:.2f}%\",\n",
    "        \"Yes\" if len(history.history['accuracy']) < EPOCHS else \"No (Reached max epochs)\",\n",
    "        \"Yes\" if len(history.history['accuracy']) < EPOCHS else \"No\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "\n",
    "print(\"\\n📊 PERFORMANCE METRICS\")\n",
    "print(\"─\"*50)\n",
    "display(df_metrics.style.hide(axis='index').set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'border': '1px solid black',\n",
    "    'font-size': '12px'\n",
    "}).set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#FF9800'), \n",
    "                                  ('color', 'white'), \n",
    "                                  ('font-weight', 'bold'),\n",
    "                                  ('border', '1px solid black')]}\n",
    "]))\n",
    "\n",
    "# Save summary\n",
    "df_config.to_csv('model_configuration.csv', index=False)\n",
    "df_metrics.to_csv('model_performance_metrics.csv', index=False)\n",
    "print(\"\\n✅ Configuration saved to 'model_configuration.csv'\")\n",
    "print(\"✅ Performance metrics saved to 'model_performance_metrics.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d975835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📋 Table 3: Per-Class Performance Metrics\n",
    "print(\"=\"*100)\n",
    "print(\"🎯 PER-CLASS PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Generate predictions for detailed metrics\n",
    "val_generator.reset()\n",
    "y_pred_proba = model.predict(val_generator, verbose=1)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Calculate per-class metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "precision, recall, f1, support = precision_recall_fscore_support(y_true, y_pred, average=None)\n",
    "\n",
    "class_metrics = {\n",
    "    'Disease Class': class_names,\n",
    "    'Precision': [f\"{p:.4f} ({p*100:.2f}%)\" for p in precision],\n",
    "    'Recall': [f\"{r:.4f} ({r*100:.2f}%)\" for r in recall],\n",
    "    'F1-Score': [f\"{f:.4f} ({f*100:.2f}%)\" for f in f1],\n",
    "    'Support (Samples)': support.astype(int),\n",
    "    'Accuracy': [f\"{accuracy_score(y_true[y_true==i], y_pred[y_true==i]):.4f}\" \n",
    "                 if len(y_true[y_true==i]) > 0 else \"N/A\" for i in range(len(class_names))]\n",
    "}\n",
    "\n",
    "df_class_metrics = pd.DataFrame(class_metrics)\n",
    "\n",
    "# Add average row\n",
    "avg_row = pd.DataFrame({\n",
    "    'Disease Class': ['OVERALL AVERAGE'],\n",
    "    'Precision': [f\"{precision.mean():.4f} ({precision.mean()*100:.2f}%)\"],\n",
    "    'Recall': [f\"{recall.mean():.4f} ({recall.mean()*100:.2f}%)\"],\n",
    "    'F1-Score': [f\"{f1.mean():.4f} ({f1.mean()*100:.2f}%)\"],\n",
    "    'Support (Samples)': [support.sum()],\n",
    "    'Accuracy': [f\"{accuracy_score(y_true, y_pred):.4f}\"]\n",
    "})\n",
    "\n",
    "df_class_metrics = pd.concat([df_class_metrics, avg_row], ignore_index=True)\n",
    "\n",
    "# Style the dataframe\n",
    "styled_class = df_class_metrics.style.set_properties(**{\n",
    "    'text-align': 'center',\n",
    "    'border': '1px solid black',\n",
    "    'font-size': '11px'\n",
    "}).set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#9C27B0'), \n",
    "                                  ('color', 'white'), \n",
    "                                  ('font-weight', 'bold'),\n",
    "                                  ('text-align', 'center'),\n",
    "                                  ('border', '1px solid black')]}\n",
    "]).apply(lambda x: ['background-color: #FFD700; font-weight: bold'] * len(x) \n",
    "         if x.name == len(df_class_metrics) - 1 else [''] * len(x), axis=1)\n",
    "\n",
    "display(styled_class)\n",
    "\n",
    "# Save to CSV\n",
    "df_class_metrics.to_csv('per_class_performance.csv', index=False)\n",
    "print(\"\\n✅ Per-class performance saved to 'per_class_performance.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Advanced Accuracy Visualization with Statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Accuracy with Confidence Intervals\n",
    "ax = axes[0, 0]\n",
    "epochs_range = range(1, len(history.history['accuracy']) + 1)\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "ax.plot(epochs_range, train_acc, 'o-', linewidth=2.5, markersize=6, \n",
    "        label='Training Accuracy', color='#2ecc71', alpha=0.8)\n",
    "ax.plot(epochs_range, val_acc, 's-', linewidth=2.5, markersize=6, \n",
    "        label='Validation Accuracy', color='#e74c3c', alpha=0.8)\n",
    "ax.fill_between(epochs_range, train_acc, alpha=0.2, color='#2ecc71')\n",
    "ax.fill_between(epochs_range, val_acc, alpha=0.2, color='#e74c3c')\n",
    "ax.axhline(y=max(val_acc), color='red', linestyle='--', alpha=0.5, \n",
    "           label=f'Best Val Acc: {max(val_acc):.4f}')\n",
    "ax.set_title('Model Accuracy Progress', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Epoch', fontsize=13)\n",
    "ax.set_ylabel('Accuracy', fontsize=13)\n",
    "ax.legend(loc='lower right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "# Plot 2: Loss with Moving Average\n",
    "ax = axes[0, 1]\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Calculate moving average (window=3)\n",
    "def moving_average(data, window=3):\n",
    "    return np.convolve(data, np.ones(window)/window, mode='valid')\n",
    "\n",
    "if len(train_loss) >= 3:\n",
    "    train_ma = moving_average(train_loss)\n",
    "    val_ma = moving_average(val_loss)\n",
    "    ma_epochs = range(2, len(train_loss) + 1)\n",
    "    ax.plot(ma_epochs, train_ma, '--', linewidth=2, label='Train MA(3)', color='#3498db', alpha=0.6)\n",
    "    ax.plot(ma_epochs, val_ma, '--', linewidth=2, label='Val MA(3)', color='#f39c12', alpha=0.6)\n",
    "\n",
    "ax.plot(epochs_range, train_loss, 'o-', linewidth=2.5, markersize=6,\n",
    "        label='Training Loss', color='#3498db', alpha=0.8)\n",
    "ax.plot(epochs_range, val_loss, 's-', linewidth=2.5, markersize=6,\n",
    "        label='Validation Loss', color='#f39c12', alpha=0.8)\n",
    "ax.axhline(y=min(val_loss), color='orange', linestyle='--', alpha=0.5,\n",
    "           label=f'Best Val Loss: {min(val_loss):.4f}')\n",
    "ax.set_title('Model Loss with Moving Average', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Epoch', fontsize=13)\n",
    "ax.set_ylabel('Loss', fontsize=13)\n",
    "ax.legend(loc='upper right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# Plot 3: Accuracy Improvement Rate\n",
    "ax = axes[1, 0]\n",
    "train_acc_change = [0] + [train_acc[i] - train_acc[i-1] for i in range(1, len(train_acc))]\n",
    "val_acc_change = [0] + [val_acc[i] - val_acc[i-1] for i in range(1, len(val_acc))]\n",
    "\n",
    "ax.bar([e - 0.2 for e in epochs_range], train_acc_change, width=0.4, \n",
    "       label='Training Δ Accuracy', color='#2ecc71', alpha=0.7)\n",
    "ax.bar([e + 0.2 for e in epochs_range], val_acc_change, width=0.4,\n",
    "       label='Validation Δ Accuracy', color='#e74c3c', alpha=0.7)\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "ax.set_title('Epoch-to-Epoch Accuracy Change', fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel('Epoch', fontsize=13)\n",
    "ax.set_ylabel('Change in Accuracy', fontsize=13)\n",
    "ax.legend(loc='best', fontsize=11)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Performance Comparison Box Plot\n",
    "ax = axes[1, 1]\n",
    "performance_data = [\n",
    "    train_acc,\n",
    "    val_acc,\n",
    "    [1-l for l in train_loss],  # Convert loss to accuracy-like metric\n",
    "    [1-l for l in val_loss]\n",
    "]\n",
    "box = ax.boxplot(performance_data, labels=['Train\\nAccuracy', 'Val\\nAccuracy', \n",
    "                                             'Train\\n(1-Loss)', 'Val\\n(1-Loss)'],\n",
    "                 patch_artist=True, showmeans=True)\n",
    "\n",
    "colors = ['#2ecc71', '#e74c3c', '#3498db', '#f39c12']\n",
    "for patch, color in zip(box['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.6)\n",
    "\n",
    "ax.set_title('Training Metrics Distribution', fontsize=16, fontweight='bold')\n",
    "ax.set_ylabel('Value', fontsize=13)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('advanced_accuracy_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Advanced accuracy analysis saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f064df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📥 Download All Analysis Files\n",
    "from google.colab import files\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"📥 DOWNLOADING ALL TRAINING ANALYSIS FILES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "files_to_download = [\n",
    "    'rice_disease_model.h5',\n",
    "    'class_indices.json',\n",
    "    'confusion_matrix.png',\n",
    "    'training_curves.png',\n",
    "    'detailed_training_analysis.png',\n",
    "    'advanced_accuracy_analysis.png',\n",
    "    'training_history.csv',\n",
    "    'model_configuration.csv',\n",
    "    'model_performance_metrics.csv',\n",
    "    'per_class_performance.csv'\n",
    "]\n",
    "\n",
    "print(\"\\n📦 Downloading files...\\n\")\n",
    "for file in files_to_download:\n",
    "    try:\n",
    "        files.download(file)\n",
    "        print(f\"  ✅ {file}\")\n",
    "    except:\n",
    "        print(f\"  ⚠️ {file} - Not found (skipped)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✨ TRAINING COMPLETE - ALL FILES DOWNLOADED!\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n📊 You now have:\")\n",
    "print(\"  • Model files (rice_disease_model.h5, class_indices.json)\")\n",
    "print(\"  • Visualizations (4 PNG files)\")\n",
    "print(\"  • Detailed tables (4 CSV files)\")\n",
    "print(\"\\n🚀 Next Steps:\")\n",
    "print(\"  1. Place model files in your 'models/' folder\")\n",
    "print(\"  2. Review CSV files for detailed metrics\")\n",
    "print(\"  3. Run: python app_simple.py\")\n",
    "print(\"  4. Open: http://localhost:5000\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
